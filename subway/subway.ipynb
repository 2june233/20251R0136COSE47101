{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ccddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc3523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e6db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a996a",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f221b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '' # API key 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4734d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "\n",
    "time_of_day = 'morning' # 시간대 변경하기 (morning / afternoon / evening)\n",
    "duration_min = 120\n",
    "interval_sec = 10\n",
    "today = datetime.now().strftime('%m%d')\n",
    "filepath = f'data/{today}'\n",
    "os.makedirs(filepath, exist_ok=True)\n",
    "filename = os.path.join(filepath, f'all_{today}_{time_of_day}.csv')\n",
    "\n",
    "def collect_all_data(key):\n",
    "    try:\n",
    "        url = f'http://swopenAPI.seoul.go.kr/api/subway/{key}/xml/realtimeStationArrival/ALL'\n",
    "        response = requests.get(url)\n",
    "        response.encoding = 'utf-8'\n",
    "        root = ET.fromstring(response.content)\n",
    "        rows = root.findall('row')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'API request failed ({e})')\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if not rows:\n",
    "        print('No data received')\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    records = [{child.tag: child.text for child in row} for row in rows]\n",
    "    df = pd.DataFrame(records)\n",
    "    print(f'Collected {len(records)} records')\n",
    "    return df\n",
    "\n",
    "print(f'Starting {interval_sec} seconds interval data collection for {duration_min} minutes...\\n')\n",
    "try:\n",
    "    total_rounds = (duration_min * 60) // interval_sec\n",
    "    header_written = False\n",
    "\n",
    "    for i in range(total_rounds):\n",
    "        df_round = collect_all_data(key)\n",
    "\n",
    "        if not df_round.empty:\n",
    "            df_round.to_csv(\n",
    "                filename,\n",
    "                mode='a',\n",
    "                header=not header_written,\n",
    "                index=False,\n",
    "                encoding='utf-8-sig'\n",
    "            )\n",
    "            header_written = True\n",
    "        \n",
    "        time.sleep(interval_sec)\n",
    "    \n",
    "    print(f'\\nAll data collection saved as {filename}')\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nData collection interrupted by user')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6630fd0",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aad821",
   "metadata": {},
   "source": [
    "### 서울 도시철도 열차운행시각표 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359c75e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanghm\\AppData\\Local\\Temp\\ipykernel_6580\\3797893929.py:20: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  schedule_df = pd.read_csv(schedule_filename, encoding='cp949')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered schedule saved as 서울교통공사_서울 도시철도 열차운행시각표_20250430_morning_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanghm\\AppData\\Local\\Temp\\ipykernel_6580\\3797893929.py:20: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  schedule_df = pd.read_csv(schedule_filename, encoding='cp949')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered schedule saved as 서울교통공사_서울 도시철도 열차운행시각표_20250430_afternoon_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanghm\\AppData\\Local\\Temp\\ipykernel_6580\\3797893929.py:20: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  schedule_df = pd.read_csv(schedule_filename, encoding='cp949')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered schedule saved as 서울교통공사_서울 도시철도 열차운행시각표_20250430_evening_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 2호선 IN ↔ OUT 변환\n",
    "def reverse_direction(row):\n",
    "    if row['호선'] == 2:\n",
    "        if row['방향'] == 'IN':\n",
    "            return 'OUT'\n",
    "        elif row['방향'] == 'OUT':\n",
    "            return 'IN'\n",
    "    return row['방향']\n",
    "\n",
    "def filter_schedule(time_of_day):\n",
    "    schedule_filename = '서울교통공사_서울 도시철도 열차운행시각표_20250430.csv'\n",
    "\n",
    "    match time_of_day:\n",
    "        case 'morning':\n",
    "            start_time = datetime.strptime('07:30:00', '%H:%M:%S').time()\n",
    "            end_time = datetime.strptime('09:30:00', '%H:%M:%S').time()\n",
    "        case 'afternoon':\n",
    "            start_time = datetime.strptime('17:00:00', '%H:%M:%S').time()\n",
    "            end_time = datetime.strptime('19:00:00', '%H:%M:%S').time()\n",
    "        case 'evening':\n",
    "            start_time = datetime.strptime('21:00:00', '%H:%M:%S').time()\n",
    "            end_time = datetime.strptime('23:00:00', '%H:%M:%S').time()\n",
    "        case _:\n",
    "            raise ValueError(f'Invalid time_of_day: {time_of_day}')\n",
    "    \n",
    "    schedule_df = pd.read_csv(schedule_filename, encoding='cp949')\n",
    "    schedule_df['열차도착시간'] = pd.to_datetime(schedule_df['열차도착시간'], format='%H:%M:%S', errors='coerce')\n",
    "    schedule_df = schedule_df[schedule_df['열차도착시간'].notna()].copy()\n",
    "    schedule_df['방향'] = schedule_df.apply(reverse_direction, axis=1)\n",
    "\n",
    "    excluded_stations = ['별내별가람', '오남', '자양', '진접']\n",
    "    schedule_df = schedule_df[~schedule_df['역사명'].isin(excluded_stations)]\n",
    "\n",
    "    station_name_map = {\n",
    "        '공릉': '공릉(서울산업대입구)',\n",
    "        '광나루': '광나루(장신대)',\n",
    "        '군자': '군자(능동)',\n",
    "        '굽은다리': '굽은다리(강동구민회관앞)',\n",
    "        '남한산성입구': '남한산성입구(성남법원,검찰청)',\n",
    "        '대흥': '대흥(서강대앞)',\n",
    "        '몽촌토성': '몽촌토성(평화의문)',\n",
    "        '상도': '상도(중앙대앞)',\n",
    "        '상월곡': '상월곡(한국과학기술연구원)',\n",
    "        '새절': '새절(신사)',\n",
    "        '서울역': '서울',\n",
    "        '숭실대입구': '숭실대입구(살피재)',\n",
    "        '신정': '신정(은행정)',\n",
    "        '쌍용': '쌍용(나사렛대)',\n",
    "        '아차산': '아차산(어린이대공원후문)',\n",
    "        '안암': '안암(고대병원앞)',\n",
    "        '어린이대공원': '어린이대공원(세종대)',\n",
    "        '오목교': '오목교(목동운동장앞)',\n",
    "        '월곡': '월곡(동덕여대)',\n",
    "        '월드컵경기장': '월드컵경기장(성산)',\n",
    "        '응암': '응암순환(상선)',\n",
    "        '이수': '총신대입구(이수)',\n",
    "        '증산': '증산(명지대앞)',\n",
    "        '천호': '천호(풍납토성)',\n",
    "        '총신대입구': '총신대입구(이수)',\n",
    "        '평택지제': '지제',\n",
    "        '화랑대': '화랑대(서울여대입구)'\n",
    "    }\n",
    "    schedule_df['역사명'] = schedule_df['역사명'].map(lambda x: station_name_map.get(x, x))\n",
    "\n",
    "    filtered = schedule_df[\n",
    "        (schedule_df['열차도착시간'].dt.time >= start_time) &\n",
    "        (schedule_df['열차도착시간'].dt.time <= end_time)\n",
    "    ].copy()\n",
    "\n",
    "    filtered = filtered.sort_values(by=['호선', '방향', '열차도착시간'])\n",
    "\n",
    "    output_filename = schedule_filename.replace('.csv', f'_{time_of_day}_clean.csv')\n",
    "    filtered.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "    print(f'Filtered schedule saved as {output_filename}')\n",
    "\n",
    "# 세 번 실행\n",
    "for time_slots in ['morning', 'afternoon', 'evening']:\n",
    "    filter_schedule(time_slots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075425b",
   "metadata": {},
   "source": [
    "### 수집 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a2233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 16개 역 데이터 전처리 (e.g. 서울_0525_morning.csv)\n",
    "\n",
    "# date = '0521' # 날짜 변경하기\n",
    "# time_of_day = 'morning' # 시간대 변경하기 (morning / afternoon / evening)\n",
    "# stations = ['강남', '고속터미널', '군포', '금정', '금천구청', '명동', '명일', '부평', '사당', '서울', '성수', '수리산', '신도림', '안암(고대병원앞)', '약수', '왕십리']\n",
    "\n",
    "# # 시간 범위 변경하기\n",
    "# start_time = datetime.strptime('07:30:00', '%H:%M:%S').time()\n",
    "# end_time = datetime.strptime('09:30:00', '%H:%M:%S').time()\n",
    "\n",
    "# columns = ['subwayId', 'updnLine', 'statnNm', 'btrainSttus', 'btrainNo', 'bstatnNm', 'recptnDt', 'arvlCd']\n",
    "\n",
    "# for station in stations:\n",
    "#     try:\n",
    "#         filename = f'data/{date}/{station}_{date}_{time_of_day}.csv'\n",
    "\n",
    "#         df = pd.read_csv(filename)\n",
    "#         df['recptnDt'] = pd.to_datetime(df['recptnDt'], errors='coerce')\n",
    "\n",
    "#         # 시간 범위 + 호선 (1-9호선만) 필터링\n",
    "#         df = df[\n",
    "#             df['recptnDt'].dt.time.between(start_time, end_time) &\n",
    "#             df['subwayId'].astype(str).str[:4].astype(int).between(1001, 1009)\n",
    "#         ]\n",
    "\n",
    "#         # 2호선\n",
    "#         is_line2 = df['subwayId'] == 1002\n",
    "#         df_line2 = df[is_line2 & (df['arvlCd'] == 5)].copy()\n",
    "#         df_line2['statnNm'] = df_line2['arvlMsg3']\n",
    "#         df_line2 = df_line2[columns]\n",
    "\n",
    "#         if not df_line2.empty:\n",
    "#             df_line2 = df_line2.sort_values('recptnDt').drop_duplicates(\n",
    "#                 subset=['btrainNo', 'subwayId', 'updnLine', 'statnNm'], keep='first'\n",
    "#             )\n",
    "#             for station_before in df_line2['statnNm'].unique():\n",
    "#                 group = df_line2[df_line2['statnNm'] == station_before]\n",
    "#                 filename_new = f'data/{date}/{station_before}_{date}_{time_of_day}_clean.csv'\n",
    "#                 group.to_csv(filename_new, index=False, encoding='utf-8-sig')\n",
    "#                 print(f'{station_before} saved as {filename_new}')\n",
    "\n",
    "#         # 그 외 호선\n",
    "#         df_other = df[~is_line2 & (df['arvlCd'] == 1)].copy()\n",
    "#         df_other = df_other[columns]\n",
    "#         if not df_other.empty:\n",
    "#             df_other = df_other.sort_values('recptnDt').drop_duplicates(\n",
    "#                 subset=['btrainNo', 'subwayId', 'updnLine', 'statnNm'], keep='first'\n",
    "#             )\n",
    "#             filename_new = f'data/{date}/{station}_{date}_{time_of_day}_clean.csv'\n",
    "#             df_other.to_csv(filename_new, index=False, encoding='utf-8-sig')\n",
    "#             print(f'{station} saved as {filename_new}')\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f'Preprocessing failed for {station} ({e})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46d0ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/0529/all_0529_evening.csv\n",
      "All preprocessing saved as data/0529/all_0529_evening_clean.csv\n",
      "Processing: data/0530/all_0530_evening.csv\n",
      "All preprocessing saved as data/0530/all_0530_evening_clean.csv\n",
      "Processing: data/0531/all_0531_evening.csv\n",
      "All preprocessing saved as data/0531/all_0531_evening_clean.csv\n",
      "Processing: data/0601/all_0601_morning.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanghm\\AppData\\Local\\Temp\\ipykernel_18280\\1574707523.py:25: DtypeWarning: Columns (12,13,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_all = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All preprocessing saved as data/0601/all_0601_morning_clean.csv\n",
      "Processing: data/0602/all_0602_evening.csv\n",
      "All preprocessing saved as data/0602/all_0602_evening_clean.csv\n",
      "Processing: data/0603/all_0603_morning.csv\n",
      "All preprocessing saved as data/0603/all_0603_morning_clean.csv\n",
      "Processing: data/0604/all_0604_morning.csv\n",
      "All preprocessing saved as data/0604/all_0604_morning_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# 일괄 데이터 전처리 (e.g. all_0529_morning.csv)\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "seongsu_branch = {'성수지선', '용답', '신답', '용두', '신설동'}\n",
    "sinjeong_branch = {'신도림지선', '도림천', '양천구청', '신정네거리', '까치산'}\n",
    "\n",
    "def convert_direction(row):\n",
    "    line = row['subwayId']\n",
    "    station = row['statnNm']\n",
    "    direction = row['updnLine']\n",
    "    destination = row['bstatnNm']\n",
    "    if line == 1002:\n",
    "        if station == '성수' and destination == '성수지선':\n",
    "            return '하행' if direction == '내선' else '상행'\n",
    "        elif station == '신도림' and destination == '신도림지선':\n",
    "            return '상행' if direction == '내선' else '하행'\n",
    "        elif station in seongsu_branch and destination in seongsu_branch:\n",
    "            return '하행' if direction == '내선' else '상행'\n",
    "        elif station in sinjeong_branch and destination in sinjeong_branch:\n",
    "            return '상행' if direction == '내선' else '하행'\n",
    "    return direction\n",
    "\n",
    "def preprocess_file(date, time_of_day):\n",
    "    filename = f'data/{date}/all_{date}_{time_of_day}.csv'\n",
    "\n",
    "    match time_of_day:\n",
    "        case 'morning':\n",
    "            start_time = datetime.strptime('07:30:00', '%H:%M:%S').time()\n",
    "            end_time = datetime.strptime('09:30:00', '%H:%M:%S').time()\n",
    "        case 'afternoon':\n",
    "            start_time = datetime.strptime('17:00:00', '%H:%M:%S').time()\n",
    "            end_time = datetime.strptime('19:00:00', '%H:%M:%S').time()\n",
    "        case 'evening':\n",
    "            start_time = datetime.strptime('21:00:00', '%H:%M:%S').time()\n",
    "            end_time = datetime.strptime('23:00:00', '%H:%M:%S').time()\n",
    "        case _:\n",
    "            raise ValueError(f'Invalid time_of_day: {time_of_day}')\n",
    "    \n",
    "    columns = ['subwayId', 'updnLine', 'statnNm', 'btrainSttus', 'btrainNo', 'bstatnNm', 'recptnDt', 'arvlCd']\n",
    "\n",
    "    try:\n",
    "        df_all = pd.read_csv(filename)\n",
    "        df_all['recptnDt'] = pd.to_datetime(df_all['recptnDt'], errors='coerce')\n",
    "\n",
    "        # 시간 범위 + 호선 (1-9호선만) 필터링\n",
    "        df_all = df_all[\n",
    "            df_all['recptnDt'].dt.time.between(start_time, end_time) &\n",
    "            df_all['subwayId'].astype(str).str[:4].astype(int).between(1001, 1009)\n",
    "        ]\n",
    "\n",
    "        # ——————————————————————————————\n",
    "        # 2호선\n",
    "\n",
    "        # 방향 보정\n",
    "        df_all['updnLine'] = df_all.apply(convert_direction, axis=1)\n",
    "\n",
    "        is_line2 = df_all['subwayId'] == 1002\n",
    "\n",
    "        # arvlCd == 5: 전역 도착 (arvlMsg3의 전역을 statnNm으로)\n",
    "        df2_5 = df_all[is_line2 & (df_all['arvlCd'] == 5)].copy()\n",
    "        df2_5 = df2_5[df2_5['arvlMsg3'].notna()]\n",
    "        df2_5['statnNm'] = df2_5['arvlMsg3']\n",
    "\n",
    "        # 종합운동장 → 삼성 (recptnDt 시간 보정)\n",
    "        df_samseong = df_all[\n",
    "            is_line2 &\n",
    "            (df_all['statnNm'] == '삼성') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '종합운동장')\n",
    "        ].copy()\n",
    "        df_samseong['recptnDt'] = df_samseong['recptnDt'] + timedelta(minutes=1)\n",
    "\n",
    "        # 역삼 → 선릉 (recptnDt 시간 보정)\n",
    "        df_seolleung = df_all[\n",
    "            is_line2 &\n",
    "            (df_all['statnNm'] == '선릉') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '역삼')\n",
    "        ].copy()\n",
    "        df_seolleung['recptnDt'] = df_seolleung['recptnDt'] + timedelta(minutes=1)\n",
    "\n",
    "        # 한양대 → 뚝섬 (recptnDt 시간 보정)\n",
    "        df_ttuksom = df_all[\n",
    "            is_line2 &\n",
    "            (df_all['statnNm'] == '뚝섬') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '한양대')\n",
    "        ].copy()\n",
    "        df_ttuksom['recptnDt'] = df_ttuksom['recptnDt'] + timedelta(minutes=1)\n",
    "\n",
    "        # 성수 → 건대입구 (성수 도착 = 성수 출발 - recptnDt)\n",
    "        df_seongsu = df_all[\n",
    "            is_line2 &\n",
    "            (df_all['statnNm'] == '건대입구') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '성수')\n",
    "        ].copy()\n",
    "        df_seongsu = df_seongsu[df_seongsu['arvlMsg3'].notna()]\n",
    "        df_seongsu['statnNm'] = df_seongsu['arvlMsg3']\n",
    "        df_seongsu['recptnDt'] = df_seongsu['recptnDt'] - timedelta(minutes=0.5)\n",
    "\n",
    "        # 건대입구 → 성수 (recptnDt 시간 보정)\n",
    "        df_konkukuniv_to_seongsu = df_all[\n",
    "            is_line2 &\n",
    "            (df_all['statnNm'] == '성수') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '건대입구')\n",
    "        ].copy()\n",
    "        df_konkukuniv_to_seongsu['recptnDt'] = df_konkukuniv_to_seongsu['recptnDt'] + timedelta(minutes=1)\n",
    "\n",
    "        # 용두 → 신설동 (recptnDt 시간 보정)\n",
    "        df_sinseoldong = df_all[\n",
    "            is_line2 &\n",
    "            (df_all['statnNm'] == '신설동') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '용두')\n",
    "        ].copy()\n",
    "        df_sinseoldong['recptnDt'] = df_sinseoldong['recptnDt'] + timedelta(minutes=1)\n",
    "\n",
    "        # 신답 → 용답 (recptnDt 시간 보정)\n",
    "        df_yongdap = df_all[\n",
    "            is_line2 &\n",
    "            (df_all['statnNm'] == '용답') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '신답')\n",
    "        ].copy()\n",
    "        df_yongdap['recptnDt'] = df_yongdap['recptnDt'] + timedelta(minutes=1)\n",
    "\n",
    "        # 용답 → 성수 (recptnDt 시간 보정)\n",
    "        df_yongdap_to_seongsu = df_yongdap.copy()\n",
    "        df_yongdap_to_seongsu['statnNm'] = '성수'\n",
    "        df_yongdap_to_seongsu['recptnDt'] = df_yongdap_to_seongsu['recptnDt'] + timedelta(minutes=3)\n",
    "\n",
    "        # 신정네거리 → 까치산 (recptnDt 시간 보정)\n",
    "        df_kkachisan = df_all[\n",
    "            is_line2 &\n",
    "            (df_all['statnNm'] == '까치산') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '신정네거리')\n",
    "        ].copy()\n",
    "        df_kkachisan['recptnDt'] = df_kkachisan['recptnDt'] + timedelta(minutes=2)\n",
    "\n",
    "        # 양천구청 → 도림천 (recptnDt 시간 보정)\n",
    "        df_dorimcheon = df_all[\n",
    "            is_line2 &\n",
    "            (df_all['statnNm'] == '도림천') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '양천구청')\n",
    "        ].copy()\n",
    "        df_dorimcheon['recptnDt'] = df_dorimcheon['recptnDt'] + timedelta(minutes=2)\n",
    "\n",
    "        # 도림천 → 신도림 (recptnDt 시간 보정)\n",
    "        df_dorimcheon_to_sindorim = df_dorimcheon.copy()\n",
    "        df_dorimcheon_to_sindorim['statnNm'] = '신도림'\n",
    "        df_dorimcheon_to_sindorim['recptnDt'] = df_dorimcheon_to_sindorim['recptnDt'] + timedelta(minutes=1)\n",
    "\n",
    "        # 병합\n",
    "        df_line2 = pd.concat([\n",
    "            df2_5,\n",
    "            df_samseong,\n",
    "            df_seolleung,\n",
    "            df_ttuksom,\n",
    "            df_seongsu,\n",
    "            df_konkukuniv_to_seongsu,\n",
    "            df_sinseoldong,\n",
    "            df_yongdap,\n",
    "            df_yongdap_to_seongsu,\n",
    "            df_kkachisan,\n",
    "            df_dorimcheon,\n",
    "            df_dorimcheon_to_sindorim],\n",
    "            ignore_index=True)\n",
    "        df_line2['priority'] = df_line2['arvlCd'].apply(lambda x: 0 if x == 5 else 1) # arvlCd == 5에 priority 부여\n",
    "\n",
    "        # priority 기준으로 먼저 정렬한 후 중복 제거\n",
    "        df_line2 = df_line2.sort_values(by=['btrainNo', 'subwayId', 'updnLine', 'statnNm', 'priority'])\n",
    "        df_line2 = df_line2.drop_duplicates(\n",
    "            subset=['btrainNo', 'subwayId', 'updnLine', 'statnNm'], keep='first'\n",
    "        )\n",
    "        df_line2 = df_line2.drop(columns='priority')\n",
    "\n",
    "        # ——————————————————————————————\n",
    "        # 9호선\n",
    "        is_line9 = df_all['subwayId'] == 1009\n",
    "\n",
    "        # arvlCd == 5: 전역 도착 (arvlMsg3의 전역을 statnNm으로)\n",
    "        df9_5 = df_all[is_line9 & (df_all['arvlCd'] == 5)].copy()\n",
    "        df9_5 = df9_5[df9_5['arvlMsg3'].notna()]\n",
    "        df9_5['statnNm'] = df9_5['arvlMsg3']\n",
    "        df9_5['priority'] = 0\n",
    "\n",
    "        # 김포공항 → 개화 (recptnDt 시간 보정)\n",
    "        df_gaehwa = df_all[\n",
    "            is_line9 &\n",
    "            (df_all['statnNm'] == '개화') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '김포공항')\n",
    "        ].copy()\n",
    "        df_gaehwa['recptnDt'] = df_gaehwa['recptnDt'] + timedelta(minutes=4)\n",
    "        df_gaehwa['priority'] = 1\n",
    "\n",
    "        # 둔촌오륜 → 중앙보훈병원 (recptnDt 시간 보정)\n",
    "        df_vhsmedicalcenter = df_all[\n",
    "            is_line9 &\n",
    "            (df_all['statnNm'] == '중앙보훈병원') &\n",
    "            (df_all['arvlCd'] == 3) &\n",
    "            (df_all['arvlMsg3'] == '둔촌오륜')\n",
    "        ].copy()\n",
    "        df_vhsmedicalcenter['recptnDt'] = df_vhsmedicalcenter['recptnDt'] + timedelta(minutes=2)\n",
    "        df_vhsmedicalcenter['priority'] = 1\n",
    "\n",
    "        # 병합\n",
    "        df_line9 = pd.concat([df9_5, df_gaehwa, df_vhsmedicalcenter], ignore_index=True)\n",
    "        df_line9 = df_line9.sort_values(by=['btrainNo', 'subwayId', 'updnLine', 'statnNm', 'priority'])\n",
    "        df_line9 = df_line9.drop_duplicates(\n",
    "            subset=['btrainNo', 'subwayId', 'updnLine', 'statnNm'], keep='first'\n",
    "        )\n",
    "        df_line9 = df_line9.drop(columns='priority')\n",
    "\n",
    "        # ——————————————————————————————\n",
    "        # 그 외 호선\n",
    "        mask = (\n",
    "            (~is_line2) &\n",
    "            (df_all['arvlCd'] == 1) &\n",
    "            df_all['arvlMsg3'].notna() &\n",
    "            (df_all['arvlMsg3'] == df_all['statnNm'])\n",
    "        )\n",
    "        df_other = df_all.loc[mask].copy()\n",
    "\n",
    "        # 2) recptnDt 오름차순 정렬 → 가장 빠른 행이 맨 위로\n",
    "        df_other = df_other.sort_values('recptnDt')\n",
    "\n",
    "        # 3) 그룹별(열차번호·호선·방향·역명)로 가장 첫 행만 남기기\n",
    "        df_other = df_other.drop_duplicates(\n",
    "            subset=['btrainNo', 'subwayId', 'updnLine', 'statnNm'],\n",
    "            keep='first'\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        # ——————————————————————————————\n",
    "        # 전체\n",
    "        df_clean = pd.concat([df_line2, df_line9, df_other], ignore_index=True)\n",
    "        df_clean = df_clean.sort_values('recptnDt')[columns]\n",
    "        df_clean = df_clean[~df_clean['statnNm'].isin(['성수지선', '신도림지선'])]\n",
    "        filename_new = f'data/{date}/all_{date}_{time_of_day}_clean.csv'\n",
    "        os.makedirs(os.path.dirname(filename_new), exist_ok=True)\n",
    "        df_clean.to_csv(filename_new, index=False, encoding='utf-8-sig')\n",
    "        print(f'All preprocessing saved as {filename_new}')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Preprocessing failed ({e})')\n",
    "\n",
    "base_dir = 'data'\n",
    "time_slots = ['morning', 'afternoon', 'evening']\n",
    "\n",
    "# 하위 폴더 중 숫자 4~5자리 (e.g. '0529')인 것만 날짜로 간주\n",
    "date_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d)) and d.isdigit()]\n",
    "\n",
    "for date in sorted(date_dirs):\n",
    "    for time_of_day in time_slots:\n",
    "        filename = f'{base_dir}/{date}/all_{date}_{time_of_day}.csv'\n",
    "        filename_new = f'data/{date}/all_{date}_{time_of_day}_clean.csv'\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "            print(f'Processing: {filename}')\n",
    "            preprocess_file(date, time_of_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f710d",
   "metadata": {},
   "source": [
    "## Delay Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705dbf98",
   "metadata": {},
   "source": [
    "### 열차번호 기준 (현재 사용 안 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9151f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석 완료: data/0529/new_delay_0529_morning.csv\n",
      "       열차번호  호선    방향     역사명  급행코드  도착역                예정시간  \\\n",
      "21367  7079   7  DOWN     도봉산     0   석남                 NaT   \n",
      "15978  6037   6  DOWN  새절(신사)     0  봉화산                 NaT   \n",
      "21567  7083   7  DOWN      장암     0   석남                 NaT   \n",
      "21878  7091   7  DOWN      장암     0   온수                 NaT   \n",
      "21023  7071   7  DOWN      중계     0   석남 2025-05-29 07:30:10   \n",
      "\n",
      "                     실제시간   지연시간(분)  \n",
      "21367 2025-05-29 07:30:00       NaN  \n",
      "15978 2025-05-29 07:30:00       NaN  \n",
      "21567 2025-05-29 07:30:00       NaN  \n",
      "21878 2025-05-29 07:30:00       NaN  \n",
      "21023 2025-05-29 07:30:00 -0.166667  \n"
     ]
    }
   ],
   "source": [
    "date = '0529'\n",
    "time_of_day = 'morning' # 시간대 변경하기 (morning / afternoon / evening)\n",
    "year = 2025\n",
    "realtime_path = f'data/{date}/all_{date}_{time_of_day}_clean.csv'\n",
    "schedule_path = f'서울교통공사_서울 도시철도 열차운행시각표_20250430_{time_of_day}_clean.csv'\n",
    "output_path = f'data/{date}/new_delay_{date}_{time_of_day}.csv'\n",
    "\n",
    "realtime_df = pd.read_csv(realtime_path)\n",
    "schedule_df = pd.read_csv(schedule_path)\n",
    "\n",
    "analysis_day = datetime.strptime(f'{year}{date}', '%Y%m%d')\n",
    "weekday = analysis_day.weekday()\n",
    "day_type = 'DAY' if weekday < 5 else 'SAT' if weekday == 5 else 'END'\n",
    "schedule_df = schedule_df[schedule_df['주중주말'] == day_type].copy()\n",
    "\n",
    "subway_map = {\n",
    "    1001: 1, 1002: 2, 1003: 3, 1004: 4, 1005: 5,\n",
    "    1006: 6, 1007: 7, 1008: 8, 1009: 9\n",
    "}\n",
    "direction_map = {\n",
    "    '상행': 'UP',\n",
    "    '하행': 'DOWN',\n",
    "    '내선': 'IN',\n",
    "    '외선': 'OUT'\n",
    "}\n",
    "\n",
    "realtime_df['recptnDt'] = pd.to_datetime(realtime_df['recptnDt'], errors='coerce')\n",
    "realtime_df['호선'] = realtime_df['subwayId'].map(subway_map)\n",
    "realtime_df['방향'] = realtime_df['updnLine'].map(direction_map)\n",
    "realtime_df['역사명'] = realtime_df['statnNm']\n",
    "realtime_df['열차번호'] = realtime_df['btrainNo'].astype(str).str.extract(r'(\\d+)')\n",
    "realtime_df['급행코드'] = realtime_df['btrainSttus'].map({'급행': 1, '일반': 0}).fillna(0).astype(int)\n",
    "realtime_df['도착역'] = realtime_df['bstatnNm']\n",
    "\n",
    "schedule_df['열차도착시간'] = pd.to_datetime(schedule_df['열차도착시간'], errors='coerce')\n",
    "schedule_df['예정시간'] = schedule_df['열차도착시간'].dt.strftime('%H:%M:%S')\n",
    "schedule_df['예정시간'] = pd.to_datetime(\n",
    "    f'{year}-{date[:2]}-{date[2:]}' + ' ' + schedule_df['예정시간'],\n",
    "    format='%Y-%m-%d %H:%M:%S',\n",
    "    errors='coerce'\n",
    ")\n",
    "schedule_df['열차번호'] = schedule_df['열차코드'].astype(str).str.extract(r'(\\d+)')\n",
    "schedule_df['급행코드'] = schedule_df['급행여부'].fillna(0).astype(int)\n",
    "schedule_df['도착역'] = schedule_df['도착역']\n",
    "\n",
    "merged = pd.merge(\n",
    "    realtime_df,\n",
    "    schedule_df,\n",
    "    how='outer',\n",
    "    on=['열차번호', '호선', '방향', '역사명', '급행코드', '도착역']\n",
    ")\n",
    "\n",
    "merged['실제시간'] = merged['recptnDt']\n",
    "merged['지연시간(분)'] = (merged['실제시간'] - merged['예정시간']).dt.total_seconds() / 60\n",
    "\n",
    "result = merged[['열차번호', '호선', '방향', '역사명', '급행코드', '도착역', '예정시간', '실제시간', '지연시간(분)']]\n",
    "result = result.sort_values('실제시간')\n",
    "result.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'분석 완료: {output_path}')\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14674b6f",
   "metadata": {},
   "source": [
    "### ASOF, 모든 행 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2acc110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running asof match: 0529 morning\n",
      "Running asof match: 0529 afternoon\n",
      "Running asof match: 0529 evening\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ——————————————————————————————\n",
    "# 1) Asof 기반 1:1 매칭 함수 정의 (역별 매칭, 도착역 무시)\n",
    "# ——————————————————————————————\n",
    "def asof_one_to_one_match_by_station(sched_df, real_df, tol=timedelta(minutes=10)):\n",
    "    \"\"\"\n",
    "    sched_df: ‘예정시간’, ‘열차번호’ 컬럼이 있는 DataFrame (이미 호선·방향·역사명·급행코드로 필터된 상태)\n",
    "    real_df:  ‘recptnDt’,   ‘열차번호’ 컬럼이 있는 DataFrame (같은 호선·방향·역사명·급행코드)\n",
    "    tol:       최대 허용 시간차 (timedelta)\n",
    "\n",
    "    반환: [\n",
    "      {\n",
    "        'sched_idx':…, 'real_idx':…,\n",
    "        'sched_train':…, 'real_train':…,\n",
    "        '예정시간':…, '실제시간':…, '지연시간(분)':…\n",
    "      }, …\n",
    "    ]\n",
    "    - 스케줄마다 asof으로 가장 가까운 실시간을 찾고(diff = |예정 – 실제|),\n",
    "    - diff ≤ tol 페어만 남긴 뒤,\n",
    "    - 각 실시간이 여러 스케줄에 매칭되면(diff가 가장 작은 스케줄만 KEEP),\n",
    "      나머지는 매칭되지 않음(스케줄 쪽은 실제시간=NaT),\n",
    "    - 매칭되지 않은 실시간은 따로 ‘실제시간만’ 남김.\n",
    "    \"\"\"\n",
    "    # 1. 원본 인덱스 보존용 복사\n",
    "    sched = sched_df.reset_index().rename(columns={'index': 'sched_idx'})\n",
    "    real  = real_df.reset_index().rename(columns={'index': 'real_idx'})\n",
    "\n",
    "    # 2. 시간순 정렬 (merge_asof 전제)\n",
    "    sched = sched.sort_values('예정시간').reset_index(drop=True)\n",
    "    real  = real.sort_values('recptnDt').reset_index(drop=True)\n",
    "\n",
    "    # 3. merge_asof 수행 (direction='nearest', tolerance=tol)\n",
    "    merged = pd.merge_asof(\n",
    "        sched[['sched_idx','예정시간','열차번호']],\n",
    "        real[['real_idx','recptnDt','열차번호']],\n",
    "        left_on='예정시간',\n",
    "        right_on='recptnDt',\n",
    "        direction='nearest',\n",
    "        tolerance=tol,\n",
    "        suffixes=('_sched','_real')\n",
    "    )\n",
    "\n",
    "    # 4. 시간차 계산\n",
    "    merged['delay_sec'] = (merged['recptnDt'] - merged['예정시간']).dt.total_seconds()\n",
    "    merged['diff_sec'] = merged['delay_sec'].abs()\n",
    "\n",
    "    merged['matched_real'] = merged['delay_sec'].between(-180, 900)\n",
    "\n",
    "    # 5. “1:N 매칭 방지”: 매칭된(real_idx) 중에서 diff가 가장 작은 sched_idx만 남기기\n",
    "    matched = merged[merged['matched_real']].copy()\n",
    "    if not matched.empty:\n",
    "        matched = matched.sort_values(['real_idx','diff_sec'])\n",
    "        matched = matched.drop_duplicates(subset=['real_idx'], keep='first')\n",
    "\n",
    "    used_sched = set(matched['sched_idx']) if not matched.empty else set()\n",
    "    used_real  = set(matched['real_idx'])  if not matched.empty else set()\n",
    "\n",
    "    results = []\n",
    "    # 6. 매칭된 페어 추가\n",
    "    for _, row in matched.iterrows():\n",
    "        results.append({\n",
    "            'sched_idx':    int(row['sched_idx']),\n",
    "            'real_idx':     int(row['real_idx']),\n",
    "            'sched_train':  row['열차번호_sched'],\n",
    "            'real_train':   row['열차번호_real'],\n",
    "            '예정시간':     row['예정시간'],\n",
    "            '실제시간':     row['recptnDt'],\n",
    "            '지연시간(분)':  row['delay_sec'] / 60\n",
    "        })\n",
    "\n",
    "    # 7. 매칭 안 된 스케줄: 실제시간=NaT\n",
    "    for _, row in sched.iterrows():\n",
    "        idx = row['sched_idx']\n",
    "        if idx not in used_sched:\n",
    "            results.append({\n",
    "                'sched_idx':    int(idx),\n",
    "                'real_idx':     np.nan,\n",
    "                'sched_train':  row['열차번호'],\n",
    "                'real_train':   pd.NA,\n",
    "                '예정시간':     row['예정시간'],\n",
    "                '실제시간':     pd.NaT,\n",
    "                '지연시간(분)':  np.nan\n",
    "            })\n",
    "\n",
    "    # 8. 매칭 안 된 실시간: 예정시간=NaT\n",
    "    for _, row in real.iterrows():\n",
    "        idx = row['real_idx']\n",
    "        if idx not in used_real:\n",
    "            results.append({\n",
    "                'sched_idx':    np.nan,\n",
    "                'real_idx':     int(idx),\n",
    "                'sched_train':  pd.NA,\n",
    "                'real_train':   row['열차번호'],\n",
    "                '예정시간':     pd.NaT,\n",
    "                '실제시간':     row['recptnDt'],\n",
    "                '지연시간(분)':  np.nan\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "# ——————————————————————————————\n",
    "# 2) 전체 분석 스크립트\n",
    "# ——————————————————————————————\n",
    "\n",
    "def run_asof_matching(date, year, realtime_path, schedule_path, output_path):\n",
    "\n",
    "    # 1) CSV 읽기\n",
    "    realtime_df = pd.read_csv(realtime_path)\n",
    "    schedule_df = pd.read_csv(schedule_path)\n",
    "\n",
    "    # 2) 요일별 필터\n",
    "    analysis_day = datetime.strptime(f'{year}{date}', '%Y%m%d')\n",
    "    weekday      = analysis_day.weekday()\n",
    "    if date in ['0603', '0606']: # 공휴일\n",
    "        day_type = 'END'\n",
    "    else:\n",
    "        day_type = 'DAY' if weekday < 5 else 'SAT' if weekday == 5 else 'END'\n",
    "    schedule_df  = schedule_df[schedule_df['주중주말'] == day_type].copy()\n",
    "\n",
    "    # 3) 컬럼 전처리\n",
    "    subway_map    = {1001:1,1002:2,1003:3,1004:4,1005:5,1006:6,1007:7,1008:8,1009:9}\n",
    "    direction_map = {'상행':'UP','하행':'DOWN','내선':'IN','외선':'OUT'}\n",
    "\n",
    "    realtime_df['recptnDt']  = pd.to_datetime(realtime_df['recptnDt'], errors='coerce')\n",
    "    realtime_df['호선']      = realtime_df['subwayId'].map(subway_map)\n",
    "    realtime_df['방향']      = realtime_df['updnLine'].map(direction_map)\n",
    "    realtime_df['역사명']    = realtime_df['statnNm']\n",
    "    realtime_df['열차번호']  = realtime_df['btrainNo'].astype(str).str.extract(r'(\\d+)')\n",
    "    realtime_df['급행코드']  = realtime_df['btrainSttus'].map({'급행':1,'일반':0}).fillna(0).astype(int)\n",
    "    realtime_df['도착역']    = realtime_df['bstatnNm']\n",
    "\n",
    "    schedule_df['열차도착시간'] = pd.to_datetime(schedule_df['열차도착시간'], errors='coerce')\n",
    "    schedule_df['예정시간']      = schedule_df['열차도착시간'].dt.strftime('%H:%M:%S')\n",
    "    schedule_df['예정시간']      = pd.to_datetime(\n",
    "        f'{year}-{date[:2]}-{date[2:]}' + ' ' + schedule_df['예정시간'],\n",
    "        format='%Y-%m-%d %H:%M:%S', errors='coerce'\n",
    "    )\n",
    "    schedule_df['열차번호'] = schedule_df['열차코드'].astype(str).str.extract(r'(\\d+)')\n",
    "    schedule_df['급행코드'] = schedule_df['급행여부'].fillna(0).astype(int)\n",
    "    schedule_df['도착역']   = schedule_df['도착역']\n",
    "    schedule_df['역사명']   = schedule_df['역사명']\n",
    "\n",
    "    realtime_df = realtime_df.reset_index(drop=True)\n",
    "    schedule_df = schedule_df.reset_index(drop=True)\n",
    "\n",
    "    # 4) 그룹별 매칭 실행 (호선, 방향, 역사명, 급행코드)\n",
    "    group_keys = ['호선', '방향', '역사명', '급행코드']\n",
    "\n",
    "    all_matches = []\n",
    "    for key_vals, sched_grp in schedule_df.groupby(group_keys):\n",
    "        line_id, direction, station, express_code = key_vals\n",
    "\n",
    "        # 동일 그룹 실시간 추출\n",
    "        cond = (\n",
    "            (realtime_df['호선'] == line_id) &\n",
    "            (realtime_df['방향'] == direction) &\n",
    "            (realtime_df['역사명'] == station) &\n",
    "            (realtime_df['급행코드'] == express_code)\n",
    "        )\n",
    "        real_grp = realtime_df[cond].copy()\n",
    "\n",
    "        # asof 기반 1:1 매칭 (역별, 도착역 무시)\n",
    "        matches = asof_one_to_one_match_by_station(\n",
    "            sched_grp[['예정시간','열차번호']],\n",
    "            real_grp[['recptnDt','열차번호']],\n",
    "            tol=timedelta(minutes=10)\n",
    "        )\n",
    "        # 각 dict에 그룹 키 정보 추가\n",
    "        for m in matches:\n",
    "            m.update({\n",
    "                '호선':     line_id,\n",
    "                '방향':     direction,\n",
    "                '역사명':   station,\n",
    "                '급행코드': express_code\n",
    "            })\n",
    "        all_matches.extend(matches)\n",
    "\n",
    "    # 5) DataFrame으로 변환\n",
    "    result_df = pd.DataFrame(all_matches)\n",
    "\n",
    "    # 6) 컬럼 순서 정리\n",
    "    cols = [\n",
    "        '호선', '방향', '역사명', '급행코드',\n",
    "        'sched_train', 'real_train',\n",
    "        '예정시간', '실제시간', '지연시간(분)'\n",
    "    ]\n",
    "    result_df = result_df[cols]\n",
    "\n",
    "    # 7) 저장\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    result_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "base_dir = 'data'\n",
    "year = 2025\n",
    "time_slots = ['morning', 'afternoon', 'evening']\n",
    "schedule_template = '서울교통공사_서울 도시철도 열차운행시각표_20250430_{}_clean.csv'\n",
    "\n",
    "date_dirs = [\n",
    "    d for d in os.listdir(base_dir)\n",
    "    if os.path.isdir(os.path.join(base_dir, d)) and d.isdigit()\n",
    "]\n",
    "\n",
    "date_dirs = ['0529']\n",
    "\n",
    "for date in sorted(date_dirs):\n",
    "    for time_of_day in time_slots:\n",
    "        realtime_path = f'{base_dir}/{date}/all_{date}_{time_of_day}_clean.csv'\n",
    "        schedule_path = schedule_template.format(time_of_day)\n",
    "        output_path   = f'{base_dir}/{date}/delay_{date}_{time_of_day}.csv'\n",
    "\n",
    "        #파일 다 지우고 다시 하고 싶으면 주석 처리\n",
    "        # if os.path.exists(output_path):\n",
    "        #     continue\n",
    "\n",
    "        if not (os.path.exists(realtime_path) and os.path.exists(schedule_path)):\n",
    "            print(f'Skipping: missing file(s) for {date} {time_of_day}')\n",
    "            continue\n",
    "\n",
    "        print(f'Running asof match: {date} {time_of_day}')\n",
    "        try:\n",
    "            run_asof_matching(date, year, realtime_path, schedule_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed for {date} {time_of_day}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599cf66",
   "metadata": {},
   "source": [
    "## 열차코드 매핑 (-2 ~ 4분) 후 asof 매칭 (사용안함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d13ae0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running asof match: 0529 morning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 192\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRunning asof match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_of_day\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[43mrun_asof_matching\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealtime_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFailed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_of_day\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mrun_asof_matching\u001b[39m\u001b[34m(date, year, realtime_path, schedule_path, output_path)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key_vals, sched_grp \u001b[38;5;129;01min\u001b[39;00m schedule_df.groupby(group_keys):\n\u001b[32m    139\u001b[39m     line, updn, station, exp = key_vals\n\u001b[32m    140\u001b[39m     cond = (\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m         \u001b[43m(\u001b[49m\u001b[43mrealtime_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m호선\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m==\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m&\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrealtime_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m방향\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m==\u001b[49m\u001b[43mupdn\u001b[49m\u001b[43m)\u001b[49m&\n\u001b[32m    143\u001b[39m         (realtime_df[\u001b[33m'\u001b[39m\u001b[33m역사명\u001b[39m\u001b[33m'\u001b[39m]==station)&\n\u001b[32m    144\u001b[39m         (realtime_df[\u001b[33m'\u001b[39m\u001b[33m급행코드\u001b[39m\u001b[33m'\u001b[39m]==exp)\n\u001b[32m    145\u001b[39m     )\n\u001b[32m    146\u001b[39m     real_grp = realtime_df[cond].copy()\n\u001b[32m    148\u001b[39m     matches = asof_one_to_one_match_by_station(\n\u001b[32m    149\u001b[39m         sched_grp[[\u001b[33m'\u001b[39m\u001b[33m예정시간\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m열차번호\u001b[39m\u001b[33m'\u001b[39m]],\n\u001b[32m    150\u001b[39m         real_grp[[\u001b[33m'\u001b[39m\u001b[33mrecptnDt\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m열차번호\u001b[39m\u001b[33m'\u001b[39m]],\n\u001b[32m    151\u001b[39m         tol=timedelta(minutes=\u001b[32m15\u001b[39m)\n\u001b[32m    152\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yanghm\\KoreaUniversity\\DataScience\\20251R0136COSE47101\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yanghm\\KoreaUniversity\\DataScience\\20251R0136COSE47101\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:70\u001b[39m, in \u001b[36mOpsMixin.__and__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__and__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__and__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_logical_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mand_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yanghm\\KoreaUniversity\\DataScience\\20251R0136COSE47101\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:6130\u001b[39m, in \u001b[36mSeries._logical_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6127\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6128\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6130\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogical_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yanghm\\KoreaUniversity\\DataScience\\20251R0136COSE47101\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:454\u001b[39m, in \u001b[36mlogical_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    451\u001b[39m     \u001b[38;5;66;03m# i.e. scalar\u001b[39;00m\n\u001b[32m    452\u001b[39m     is_other_int_dtype = lib.is_integer(rvalues)\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m res_values = \u001b[43mna_logical_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# For int vs int `^`, `|`, `&` are bitwise operators and return\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m#   integer dtypes.  Otherwise these are boolean ops\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (left.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_other_int_dtype):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yanghm\\KoreaUniversity\\DataScience\\20251R0136COSE47101\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:362\u001b[39m, in \u001b[36mna_logical_op\u001b[39m\u001b[34m(x, y, op)\u001b[39m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mna_logical_op\u001b[39m(x: np.ndarray, y, op):\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    354\u001b[39m         \u001b[38;5;66;03m# For exposition, write:\u001b[39;00m\n\u001b[32m    355\u001b[39m         \u001b[38;5;66;03m#  yarr = isinstance(y, np.ndarray)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    360\u001b[39m         \u001b[38;5;66;03m# Then Cases where this goes through without raising include:\u001b[39;00m\n\u001b[32m    361\u001b[39m         \u001b[38;5;66;03m#  (xint or xbool) and (yint or bool)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         result = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    364\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, np.ndarray):\n\u001b[32m    365\u001b[39m             \u001b[38;5;66;03m# bool-bool dtype operations should be OK, should not get here\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def asof_one_to_one_match_by_station(sched_df, real_df, tol=timedelta(minutes=15)):\n",
    "    sched = sched_df.reset_index().rename(columns={'index': 'sched_idx'})\n",
    "    real  = real_df.reset_index().rename(columns={'index': 'real_idx'})\n",
    "\n",
    "    # 시간순 정렬\n",
    "    sched = sched.sort_values('예정시간').reset_index(drop=True)\n",
    "    real  = real.sort_values('recptnDt').reset_index(drop=True)\n",
    "\n",
    "    # 1단계: 열차번호 일치 + -2분 < delay < +4분\n",
    "    exact_merged = pd.merge(\n",
    "        sched[['sched_idx','예정시간','열차번호']],\n",
    "        real[['real_idx','recptnDt','열차번호']],\n",
    "        on='열차번호'                  # join on key\n",
    "    )\n",
    "    # 수동으로 접미사 컬럼 생성 (join key에는 suffixes가 적용되지 않음)\n",
    "    exact_merged['열차번호_sched'] = exact_merged['열차번호']\n",
    "    exact_merged['열차번호_real']  = exact_merged['열차번호']\n",
    "\n",
    "    exact_merged['delay_sec'] = (exact_merged['recptnDt'] - exact_merged['예정시간']).dt.total_seconds()\n",
    "    exact_merged = exact_merged[exact_merged['delay_sec'].between(-120, 240)]\n",
    "    exact_merged['diff_sec']  = exact_merged['delay_sec'].abs()\n",
    "    exact_matched = exact_merged.sort_values(['sched_idx','diff_sec']).drop_duplicates('sched_idx')\n",
    "\n",
    "    used_sched = set(exact_matched['sched_idx'])\n",
    "    used_real  = set(exact_matched['real_idx'])\n",
    "\n",
    "    # 2단계: asof 매칭 (남은 sched, real)\n",
    "    remaining_sched = sched[~sched['sched_idx'].isin(used_sched)].copy()\n",
    "    remaining_real  = real[~real['real_idx'].isin(used_real)].copy()\n",
    "\n",
    "    if not remaining_sched.empty and not remaining_real.empty:\n",
    "        asof_merged = pd.merge_asof(\n",
    "            remaining_sched[['sched_idx','예정시간','열차번호']],\n",
    "            remaining_real[['real_idx','recptnDt','열차번호']],\n",
    "            left_on='예정시간',\n",
    "            right_on='recptnDt',\n",
    "            direction='nearest',\n",
    "            tolerance=tol,\n",
    "            suffixes=('_sched','_real')\n",
    "        )\n",
    "        asof_merged['delay_sec'] = (asof_merged['recptnDt'] - asof_merged['예정시간']).dt.total_seconds()\n",
    "        asof_merged['diff_sec']  = asof_merged['delay_sec'].abs()\n",
    "        asof_merged = asof_merged[asof_merged['delay_sec'].between(-180, 900)]\n",
    "        asof_merged = asof_merged.dropna(subset=['recptnDt'])\n",
    "        asof_matched = asof_merged.sort_values(['real_idx','diff_sec']).drop_duplicates('real_idx')\n",
    "\n",
    "        matched_df = pd.concat([exact_matched, asof_matched], ignore_index=True)\n",
    "    else:\n",
    "        matched_df = exact_matched.copy()\n",
    "\n",
    "    used_sched = set(matched_df['sched_idx'])\n",
    "    used_real  = set(matched_df['real_idx'])\n",
    "\n",
    "    # 결과 리스트 생성\n",
    "    results = []\n",
    "    for _, row in matched_df.iterrows():\n",
    "        results.append({\n",
    "            'sched_idx':    int(row['sched_idx']),\n",
    "            'real_idx':     int(row['real_idx']),\n",
    "            'sched_train':  row['열차번호_sched'],\n",
    "            'real_train':   row['열차번호_real'],\n",
    "            '예정시간':     row['예정시간'],\n",
    "            '실제시간':     row['recptnDt'],\n",
    "            '지연시간(분)':  row['delay_sec'] / 60\n",
    "        })\n",
    "\n",
    "    # 스케줄 미매칭\n",
    "    for _, row in sched.iterrows():\n",
    "        if row['sched_idx'] not in used_sched:\n",
    "            results.append({\n",
    "                'sched_idx':    int(row['sched_idx']),\n",
    "                'real_idx':     np.nan,\n",
    "                'sched_train':  row['열차번호'],\n",
    "                'real_train':   pd.NA,\n",
    "                '예정시간':     row['예정시간'],\n",
    "                '실제시간':     pd.NaT,\n",
    "                '지연시간(분)':  np.nan\n",
    "            })\n",
    "    # 실시간 미매칭\n",
    "    for _, row in real.iterrows():\n",
    "        if row['real_idx'] not in used_real:\n",
    "            results.append({\n",
    "                'sched_idx':    np.nan,\n",
    "                'real_idx':     int(row['real_idx']),\n",
    "                'sched_train':  pd.NA,\n",
    "                'real_train':   row['열차번호'],\n",
    "                '예정시간':     pd.NaT,\n",
    "                '실제시간':     row['recptnDt'],\n",
    "                '지연시간(분)':  np.nan\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "# ——————————————————————————————\n",
    "# 2) 전체 분석 스크립트\n",
    "# ——————————————————————————————\n",
    "\n",
    "def run_asof_matching(date, year, realtime_path, schedule_path, output_path):\n",
    "    # 1) CSV 읽기\n",
    "    realtime_df = pd.read_csv(realtime_path)\n",
    "    schedule_df = pd.read_csv(schedule_path)\n",
    "\n",
    "    # 2) 요일/공휴일 필터\n",
    "    analysis_day = datetime.strptime(f'{year}{date}', '%Y%m%d')\n",
    "    wd = analysis_day.weekday()\n",
    "    if date in ['0603','0606']:\n",
    "        day_type = 'END'\n",
    "    else:\n",
    "        day_type = 'DAY' if wd < 5 else 'SAT' if wd == 5 else 'END'\n",
    "    schedule_df = schedule_df[schedule_df['주중주말']==day_type].copy()\n",
    "\n",
    "    # 3) 컬럼 전처리\n",
    "    subway_map    = {1001:1,1002:2,1003:3,1004:4,1005:5,1006:6,1007:7,1008:8,1009:9}\n",
    "    direction_map = {'상행':'UP','하행':'DOWN','내선':'IN','외선':'OUT'}\n",
    "\n",
    "    realtime_df['recptnDt'] = pd.to_datetime(realtime_df['recptnDt'], errors='coerce')\n",
    "    realtime_df['호선']     = realtime_df['subwayId'].map(subway_map)\n",
    "    realtime_df['방향']     = realtime_df['updnLine'].map(direction_map)\n",
    "    realtime_df['역사명']   = realtime_df['statnNm']\n",
    "    realtime_df['열차번호'] = realtime_df['btrainNo'].astype(str).str.extract(r'(\\d+)')\n",
    "    realtime_df['급행코드'] = realtime_df['btrainSttus'].map({'급행':1,'일반':0}).fillna(0).astype(int)\n",
    "\n",
    "    schedule_df['열차도착시간'] = pd.to_datetime(schedule_df['열차도착시간'], errors='coerce')\n",
    "    schedule_df['예정시간']    = schedule_df['열차도착시간'].dt.strftime('%H:%M:%S')\n",
    "    schedule_df['예정시간']    = pd.to_datetime(\n",
    "        f'{year}-{date[:2]}-{date[2:]} ' + schedule_df['예정시간'],\n",
    "        format='%Y-%m-%d %H:%M:%S', errors='coerce'\n",
    "    )\n",
    "    schedule_df['열차번호'] = schedule_df['열차코드'].astype(str).str.extract(r'(\\d+)')\n",
    "    schedule_df['급행코드'] = schedule_df['급행여부'].fillna(0).astype(int)\n",
    "\n",
    "    realtime_df = realtime_df.reset_index(drop=True)\n",
    "    schedule_df = schedule_df.reset_index(drop=True)\n",
    "\n",
    "    # 4) 그룹별 매칭 실행\n",
    "    group_keys = ['호선','방향','역사명','급행코드']\n",
    "    all_matches = []\n",
    "    for key_vals, sched_grp in schedule_df.groupby(group_keys):\n",
    "        line, updn, station, exp = key_vals\n",
    "        cond = (\n",
    "            (realtime_df['호선']==line)&\n",
    "            (realtime_df['방향']==updn)&\n",
    "            (realtime_df['역사명']==station)&\n",
    "            (realtime_df['급행코드']==exp)\n",
    "        )\n",
    "        real_grp = realtime_df[cond].copy()\n",
    "\n",
    "        matches = asof_one_to_one_match_by_station(\n",
    "            sched_grp[['예정시간','열차번호']],\n",
    "            real_grp[['recptnDt','열차번호']],\n",
    "            tol=timedelta(minutes=15)\n",
    "        )\n",
    "        for m in matches:\n",
    "            m.update({'호선':line,'방향':updn,'역사명':station,'급행코드':exp})\n",
    "        all_matches.extend(matches)\n",
    "\n",
    "    # 5) DataFrame 변환 및 저장\n",
    "    result_df = pd.DataFrame(all_matches)[\n",
    "        ['호선','방향','역사명','급행코드','sched_train','real_train','예정시간','실제시간','지연시간(분)']\n",
    "    ]\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    result_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "base_dir = 'data'\n",
    "year = 2025\n",
    "time_slots = ['morning', 'afternoon', 'evening']\n",
    "schedule_template = '서울교통공사_서울 도시철도 열차운행시각표_20250430_{}_clean.csv'\n",
    "\n",
    "date_dirs = [\n",
    "    d for d in os.listdir(base_dir)\n",
    "    if os.path.isdir(os.path.join(base_dir, d)) and d.isdigit()\n",
    "]\n",
    "\n",
    "date_dirs = ['0529']\n",
    "\n",
    "for date in sorted(date_dirs):\n",
    "    for time_of_day in time_slots:\n",
    "        realtime_path = f'{base_dir}/{date}/all_{date}_{time_of_day}_clean.csv'\n",
    "        schedule_path = schedule_template.format(time_of_day)\n",
    "        output_path   = f'{base_dir}/{date}/delay_{date}_{time_of_day}.csv'\n",
    "\n",
    "        #파일 다 지우고 다시 하고 싶으면 주석 처리\n",
    "        # if os.path.exists(output_path):\n",
    "        #     continue\n",
    "\n",
    "        if not (os.path.exists(realtime_path) and os.path.exists(schedule_path)):\n",
    "            print(f'Skipping: missing file(s) for {date} {time_of_day}')\n",
    "            continue\n",
    "\n",
    "        print(f'Running asof match: {date} {time_of_day}')\n",
    "        try:\n",
    "            run_asof_matching(date, year, realtime_path, schedule_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed for {date} {time_of_day}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87bf7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 급행 구분 안함 -> 결과 별로임\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# # ——————————————————————————————\n",
    "# # 1) Asof 기반 1:1 매칭 함수 정의 (역별 매칭, 도착역 무시)\n",
    "# # ——————————————————————————————\n",
    "# def asof_one_to_one_match_by_station(sched_df, real_df, tol=timedelta(minutes=10)):\n",
    "#     sched = sched_df.reset_index().rename(columns={'index': 'sched_idx'})\n",
    "#     real  = real_df.reset_index().rename(columns={'index': 'real_idx'})\n",
    "\n",
    "#     sched = sched.sort_values('예정시간').reset_index(drop=True)\n",
    "#     real  = real.sort_values('recptnDt').reset_index(drop=True)\n",
    "\n",
    "#     merged = pd.merge_asof(\n",
    "#         sched[['sched_idx','예정시간','열차번호']],\n",
    "#         real[['real_idx','recptnDt','열차번호']],\n",
    "#         left_on='예정시간',\n",
    "#         right_on='recptnDt',\n",
    "#         direction='nearest',\n",
    "#         tolerance=tol,\n",
    "#         suffixes=('_sched','_real')\n",
    "#     )\n",
    "\n",
    "#     merged['diff_sec'] = (merged['recptnDt'] - merged['예정시간']).abs().dt.total_seconds()\n",
    "#     merged['delay_sec'] = (merged['recptnDt'] - merged['예정시간']).dt.total_seconds()\n",
    "#     merged['matched_real'] = ~merged['recptnDt'].isna()\n",
    "\n",
    "#     matched = merged[merged['matched_real']].copy()\n",
    "#     if not matched.empty:\n",
    "#         matched = matched.sort_values(['real_idx','diff_sec'])\n",
    "#         matched = matched.drop_duplicates(subset=['real_idx'], keep='first')\n",
    "\n",
    "#     used_sched = set(matched['sched_idx']) if not matched.empty else set()\n",
    "#     used_real  = set(matched['real_idx'])  if not matched.empty else set()\n",
    "\n",
    "#     results = []\n",
    "#     for _, row in matched.iterrows():\n",
    "#         results.append({\n",
    "#             'sched_idx':    int(row['sched_idx']),\n",
    "#             'real_idx':     int(row['real_idx']),\n",
    "#             'sched_train':  row['열차번호_sched'],\n",
    "#             'real_train':   row['열차번호_real'],\n",
    "#             '예정시간':     row['예정시간'],\n",
    "#             '실제시간':     row['recptnDt'],\n",
    "#             '지연시간(분)':  row['delay_sec'] / 60\n",
    "#         })\n",
    "\n",
    "#     for _, row in sched.iterrows():\n",
    "#         idx = row['sched_idx']\n",
    "#         if idx not in used_sched:\n",
    "#             results.append({\n",
    "#                 'sched_idx':    int(idx),\n",
    "#                 'real_idx':     np.nan,\n",
    "#                 'sched_train':  row['열차번호'],\n",
    "#                 'real_train':   pd.NA,\n",
    "#                 '예정시간':     row['예정시간'],\n",
    "#                 '실제시간':     pd.NaT,\n",
    "#                 '지연시간(분)':  np.nan\n",
    "#             })\n",
    "\n",
    "#     for _, row in real.iterrows():\n",
    "#         idx = row['real_idx']\n",
    "#         if idx not in used_real:\n",
    "#             results.append({\n",
    "#                 'sched_idx':    np.nan,\n",
    "#                 'real_idx':     int(idx),\n",
    "#                 'sched_train':  pd.NA,\n",
    "#                 'real_train':   row['열차번호'],\n",
    "#                 '예정시간':     pd.NaT,\n",
    "#                 '실제시간':     row['recptnDt'],\n",
    "#                 '지연시간(분)':  np.nan\n",
    "#             })\n",
    "\n",
    "#     return results\n",
    "\n",
    "# # ——————————————————————————————\n",
    "# # 2) 전체 분석 스크립트\n",
    "# # ——————————————————————————————\n",
    "# def run_asof_matching(date, year, realtime_path, schedule_path, output_path):\n",
    "#     realtime_df = pd.read_csv(realtime_path)\n",
    "#     schedule_df = pd.read_csv(schedule_path)\n",
    "\n",
    "#     analysis_day = datetime.strptime(f'{year}{date}', '%Y%m%d')\n",
    "#     weekday = analysis_day.weekday()\n",
    "#     if date in ['0603', '0606']:\n",
    "#         day_type = 'END'\n",
    "#     else:\n",
    "#         day_type = 'DAY' if weekday < 5 else 'SAT' if weekday == 5 else 'END'\n",
    "#     schedule_df = schedule_df[schedule_df['주중주말'] == day_type].copy()\n",
    "\n",
    "#     subway_map    = {1001:1,1002:2,1003:3,1004:4,1005:5,1006:6,1007:7,1008:8,1009:9}\n",
    "#     direction_map = {'상행':'UP','하행':'DOWN','내선':'IN','외선':'OUT'}\n",
    "\n",
    "#     realtime_df['recptnDt']  = pd.to_datetime(realtime_df['recptnDt'], errors='coerce')\n",
    "#     realtime_df['호선']      = realtime_df['subwayId'].map(subway_map)\n",
    "#     realtime_df['방향']      = realtime_df['updnLine'].map(direction_map)\n",
    "#     realtime_df['역사명']    = realtime_df['statnNm']\n",
    "#     realtime_df['열차번호']  = realtime_df['btrainNo'].astype(str).str.extract(r'(\\d+)')\n",
    "#     realtime_df['도착역']    = realtime_df['bstatnNm']\n",
    "\n",
    "#     schedule_df['열차도착시간'] = pd.to_datetime(schedule_df['열차도착시간'], errors='coerce')\n",
    "#     schedule_df['예정시간'] = schedule_df['열차도착시간'].dt.strftime('%H:%M:%S')\n",
    "#     schedule_df['예정시간'] = pd.to_datetime(\n",
    "#         f'{year}-{date[:2]}-{date[2:]}' + ' ' + schedule_df['예정시간'],\n",
    "#         format='%Y-%m-%d %H:%M:%S', errors='coerce'\n",
    "#     )\n",
    "#     schedule_df['열차번호'] = schedule_df['열차코드'].astype(str).str.extract(r'(\\d+)')\n",
    "#     schedule_df['도착역']   = schedule_df['도착역']\n",
    "#     schedule_df['역사명']   = schedule_df['역사명']\n",
    "\n",
    "#     realtime_df = realtime_df.reset_index(drop=True)\n",
    "#     schedule_df = schedule_df.reset_index(drop=True)\n",
    "\n",
    "#     # 급행코드 제외\n",
    "#     group_keys = ['호선', '방향', '역사명']\n",
    "\n",
    "#     all_matches = []\n",
    "#     for key_vals, sched_grp in schedule_df.groupby(group_keys):\n",
    "#         line_id, direction, station = key_vals\n",
    "\n",
    "#         cond = (\n",
    "#             (realtime_df['호선'] == line_id) &\n",
    "#             (realtime_df['방향'] == direction) &\n",
    "#             (realtime_df['역사명'] == station)\n",
    "#         )\n",
    "#         real_grp = realtime_df[cond].copy()\n",
    "\n",
    "#         matches = asof_one_to_one_match_by_station(\n",
    "#             sched_grp[['예정시간','열차번호']],\n",
    "#             real_grp[['recptnDt','열차번호']],\n",
    "#             tol=timedelta(minutes=10)\n",
    "#         )\n",
    "#         for m in matches:\n",
    "#             m.update({\n",
    "#                 '호선':   line_id,\n",
    "#                 '방향':   direction,\n",
    "#                 '역사명': station\n",
    "#             })\n",
    "#         all_matches.extend(matches)\n",
    "\n",
    "#     result_df = pd.DataFrame(all_matches)\n",
    "\n",
    "#     cols = [\n",
    "#         '호선', '방향', '역사명',\n",
    "#         'sched_train', 'real_train',\n",
    "#         '예정시간', '실제시간', '지연시간(분)'\n",
    "#     ]\n",
    "#     result_df = result_df[cols]\n",
    "\n",
    "#     os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "#     result_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# # 실행 루프\n",
    "# base_dir = 'data'\n",
    "# year = 2025\n",
    "# time_slots = ['morning', 'afternoon', 'evening']\n",
    "# schedule_template = '서울교통공사_서울 도시철도 열차운행시각표_20250430_{}_clean.csv'\n",
    "\n",
    "# date_dirs = [\n",
    "#     d for d in os.listdir(base_dir)\n",
    "#     if os.path.isdir(os.path.join(base_dir, d)) and d.isdigit()\n",
    "# ]\n",
    "\n",
    "# for date in sorted(date_dirs):\n",
    "#     for time_of_day in time_slots:\n",
    "#         realtime_path = f'{base_dir}/{date}/all_{date}_{time_of_day}_clean.csv'\n",
    "#         schedule_path = schedule_template.format(time_of_day)\n",
    "#         output_path   = f'{base_dir}/{date}/new_delay_{date}_{time_of_day}.csv'\n",
    "\n",
    "#         # 기존 결과 파일 있으면 skip\n",
    "#         if os.path.exists(output_path):\n",
    "#             continue\n",
    "\n",
    "#         if not (os.path.exists(realtime_path) and os.path.exists(schedule_path)):\n",
    "#             print(f'Skipping: missing file(s) for {date} {time_of_day}')\n",
    "#             continue\n",
    "\n",
    "#         print(f'Running asof match: {date} {time_of_day}')\n",
    "#         try:\n",
    "#             run_asof_matching(date, year, realtime_path, schedule_path, output_path)\n",
    "#         except Exception as e:\n",
    "#             print(f'Failed for {date} {time_of_day}: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb348f",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ca56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line = 1 # 호선 변경하기\n",
    "# time_of_day = 'morning' # 시간대 변경하기\n",
    "# dates = {\n",
    "#     'Weekday (0519)': '0519',\n",
    "#     'Weekend (0525)': '0525'\n",
    "# }\n",
    "\n",
    "# direction_label_map = {\n",
    "#     '상행': 'Up',\n",
    "#     '하행': 'Down'\n",
    "# }\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "# for idx, direction in enumerate(['상행', '하행']):\n",
    "#     ax = axes[idx]\n",
    "#     delay_all = []\n",
    "\n",
    "#     for label, date in dates.items():\n",
    "#         filename = f'서울_line{line}_{date}_{time_of_day}_delay.csv'\n",
    "#         if not os.path.exists(filename):\n",
    "#             continue\n",
    "#         df = pd.read_csv(filename)\n",
    "#         if 'updnLine' not in df.columns or df.empty:\n",
    "#             continue\n",
    "#         df_dir = df[df['updnLine'] == direction]\n",
    "#         if df_dir.empty:\n",
    "#             continue\n",
    "#         delay_all.extend(df_dir['delay_min'].dropna().tolist())\n",
    "    \n",
    "#     if not delay_all:\n",
    "#         print(f'No delay data found for direction {direction}')\n",
    "#         continue\n",
    "\n",
    "#     dmin, dmax = int(np.floor(min(delay_all))), int(np.ceil(max(delay_all)))\n",
    "#     bins = np.arange(dmin, dmax + 1)\n",
    "\n",
    "#     for label, date in dates.items():\n",
    "#         filename = f'서울_line{line}_{date}_{time_of_day}_delay.csv'\n",
    "#         if not os.path.exists(filename):\n",
    "#             continue\n",
    "#         df = pd.read_csv(filename)\n",
    "#         df_dir = df[df['updnLine'] == direction]\n",
    "#         if df_dir.empty:\n",
    "#             continue\n",
    "#         counts, edges = np.histogram(df_dir['delay_min'], bins=bins)\n",
    "#         centers = (edges[:-1] + edges[1:]) / 2\n",
    "#         ax.plot(centers, counts, label=label, marker='o')\n",
    "    \n",
    "#     label_eng = direction_label_map.get(direction, direction)\n",
    "#     ax.axvline(0, color='gray', linestyle='--', label='Scheduled Time')\n",
    "#     ax.set_title(f'{label_eng}', fontsize=13)\n",
    "#     ax.set_xlabel('Delay (minutes)')\n",
    "#     ax.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "#     ax.set_xticks(bins)\n",
    "#     if idx == 0:\n",
    "#         ax.set_ylabel('Number of subways')\n",
    "#     ax.legend()\n",
    "\n",
    "# plt.suptitle(f'Arrival Delay Distribution by Direction\\nSeoul Station Line {line} (07:30-09:30)', fontsize=15) # 시간 범위 변경하기\n",
    "# plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#— 설정 부분만 바꿔가며 사용하세요 —#\n",
    "date = '0529'                     # 예: '0529', '0603' 등\n",
    "time_of_day = 'evening'           # 'morning' / 'afternoon' / 'evening'\n",
    "#———————————————#\n",
    "\n",
    "# 1) 전처리된 all_{date}_{time_of_day}_clean.csv 파일 경로\n",
    "input_path = f'data/{date}/all_{date}_{time_of_day}.csv'\n",
    "\n",
    "# 2) 출력할 필터링 결과 파일 경로\n",
    "output_dir  = f'data/{date}/'\n",
    "output_file = f'filtered_{date}_{time_of_day}.csv'\n",
    "output_path = os.path.join(output_dir, output_file)\n",
    "\n",
    "# (폴더가 없으면 미리 생성)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 3) CSV 읽기 (recptnDt 칼럼을 datetime으로 파싱)\n",
    "df_all = pd.read_csv(input_path, encoding='utf-8-sig', parse_dates=['recptnDt'])\n",
    "\n",
    "# 4) 역사명(statnNm)이 '서울'인 행만 남기기\n",
    "#    원본 API에서는 '서울역'을 '서울'로 표기하는 경우가 많습니다.\n",
    "#    만약 '서울역'이 정확히 들어가 있다면, '==' 대신 .str.contains('서울역') 등을 사용하세요.\n",
    "filtered = df_all[df_all['subwayId'] == 1009].copy()\n",
    "\n",
    "\n",
    "# 5) 결과 저장\n",
    "filtered.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'필터링된 파일이 저장되었습니다: {output_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
